{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa29fe81-b16c-4f35-9556-1e09677a04c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 140)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c9aad17-68a3-4be0-9f6e-e93c9e04e67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walmart shape: (6435, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>05-02-2010</td>\n",
       "      <td>1643690.90</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12-02-2010</td>\n",
       "      <td>1641957.44</td>\n",
       "      <td>1</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>211.242170</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19-02-2010</td>\n",
       "      <td>1611968.17</td>\n",
       "      <td>0</td>\n",
       "      <td>39.93</td>\n",
       "      <td>2.514</td>\n",
       "      <td>211.289143</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>26-02-2010</td>\n",
       "      <td>1409727.59</td>\n",
       "      <td>0</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2.561</td>\n",
       "      <td>211.319643</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>05-03-2010</td>\n",
       "      <td>1554806.68</td>\n",
       "      <td>0</td>\n",
       "      <td>46.50</td>\n",
       "      <td>2.625</td>\n",
       "      <td>211.350143</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store        Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price         CPI  Unemployment\n",
       "0      1  05-02-2010    1643690.90             0        42.31       2.572  211.096358         8.106\n",
       "1      1  12-02-2010    1641957.44             1        38.51       2.548  211.242170         8.106\n",
       "2      1  19-02-2010    1611968.17             0        39.93       2.514  211.289143         8.106\n",
       "3      1  26-02-2010    1409727.59             0        46.63       2.561  211.319643         8.106\n",
       "4      1  05-03-2010    1554806.68             0        46.50       2.625  211.350143         8.106"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spotify shape: (8000, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>subscription_type</th>\n",
       "      <th>listening_time</th>\n",
       "      <th>songs_played_per_day</th>\n",
       "      <th>skip_rate</th>\n",
       "      <th>device_type</th>\n",
       "      <th>ads_listened_per_week</th>\n",
       "      <th>offline_listening</th>\n",
       "      <th>is_churned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>54</td>\n",
       "      <td>CA</td>\n",
       "      <td>Free</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>0.20</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>33</td>\n",
       "      <td>DE</td>\n",
       "      <td>Family</td>\n",
       "      <td>141</td>\n",
       "      <td>62</td>\n",
       "      <td>0.34</td>\n",
       "      <td>Web</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>AU</td>\n",
       "      <td>Premium</td>\n",
       "      <td>199</td>\n",
       "      <td>38</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>CA</td>\n",
       "      <td>Student</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Other</td>\n",
       "      <td>29</td>\n",
       "      <td>US</td>\n",
       "      <td>Family</td>\n",
       "      <td>250</td>\n",
       "      <td>57</td>\n",
       "      <td>0.36</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  gender  age country subscription_type  listening_time  songs_played_per_day  skip_rate device_type  ads_listened_per_week  \\\n",
       "0        1  Female   54      CA              Free              26                    23       0.20     Desktop                     31   \n",
       "1        2   Other   33      DE            Family             141                    62       0.34         Web                      0   \n",
       "2        3    Male   38      AU           Premium             199                    38       0.04      Mobile                      0   \n",
       "3        4  Female   22      CA           Student              36                     2       0.31      Mobile                      0   \n",
       "4        5   Other   29      US            Family             250                    57       0.36      Mobile                      0   \n",
       "\n",
       "   offline_listening  is_churned  \n",
       "0                  0           1  \n",
       "1                  1           0  \n",
       "2                  1           1  \n",
       "3                  1           0  \n",
       "4                  1           1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "walmart_path = \"dataset/Walmart_Sales.csv\"\n",
    "spotify_path = \"dataset/spotify_churn_dataset.csv\"\n",
    "\n",
    "df_wm = pd.read_csv(walmart_path)\n",
    "df_sp = pd.read_csv(spotify_path)\n",
    "\n",
    "print(\"Walmart shape:\", df_wm.shape)\n",
    "display(df_wm.head())\n",
    "\n",
    "print(\"\\nSpotify shape:\", df_sp.shape)\n",
    "display(df_sp.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d256cb4-5bd6-43cf-9725-824cfd162963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Walmart target: Weekly_Sales\n",
      "Detected Spotify target: is_churned\n"
     ]
    }
   ],
   "source": [
    "# Walmart target (регрессия)\n",
    "wm_target_candidates = [\"Weekly_Sales\", \"weekly_sales\", \"Sales\", \"sales\", \"Target\", \"target\"]\n",
    "wm_target = next((c for c in wm_target_candidates if c in df_wm.columns), None)\n",
    "print(\"Detected Walmart target:\", wm_target)\n",
    "\n",
    "# Spotify target (классификация)\n",
    "sp_target_candidates = [\"churn\", \"Churn\", \"is_churn\", \"IsChurn\", \"label\", \"Label\", \"target\", \"Target\", \"y\", \"is_churned\"]\n",
    "sp_target = next((c for c in sp_target_candidates if c in df_sp.columns), None)\n",
    "print(\"Detected Spotify target:\", sp_target)\n",
    "\n",
    "if wm_target is None:\n",
    "    raise ValueError(\"Не нашёл target в Walmart_Sales.csv. Укажи wm_target вручную.\")\n",
    "if sp_target is None:\n",
    "    raise ValueError(\"Не нашёл target в spotify_churn_dataset.csv. Укажи sp_target вручную.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53a29cef-547e-4abf-9889-2d028bf20004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1643690.90</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1641957.44</td>\n",
       "      <td>1</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>211.242170</td>\n",
       "      <td>8.106</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1611968.17</td>\n",
       "      <td>0</td>\n",
       "      <td>39.93</td>\n",
       "      <td>2.514</td>\n",
       "      <td>211.289143</td>\n",
       "      <td>8.106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1409727.59</td>\n",
       "      <td>0</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2.561</td>\n",
       "      <td>211.319643</td>\n",
       "      <td>8.106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1554806.68</td>\n",
       "      <td>0</td>\n",
       "      <td>46.50</td>\n",
       "      <td>2.625</td>\n",
       "      <td>211.350143</td>\n",
       "      <td>8.106</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price         CPI  Unemployment    Year  Month  WeekOfYear  Day\n",
       "0      1    1643690.90             0        42.31       2.572  211.096358         8.106  2010.0    5.0        17.0  2.0\n",
       "1      1    1641957.44             1        38.51       2.548  211.242170         8.106  2010.0   12.0        48.0  2.0\n",
       "2      1    1611968.17             0        39.93       2.514  211.289143         8.106     NaN    NaN         NaN  NaN\n",
       "3      1    1409727.59             0        46.63       2.561  211.319643         8.106     NaN    NaN         NaN  NaN\n",
       "4      1    1554806.68             0        46.50       2.625  211.350143         8.106  2010.0    5.0        18.0  3.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date processed from: Date\n"
     ]
    }
   ],
   "source": [
    "df_wm_reg = df_wm.copy()\n",
    "\n",
    "date_col_candidates = [\"Date\", \"date\", \"DATE\"]\n",
    "date_col = next((c for c in date_col_candidates if c in df_wm_reg.columns), None)\n",
    "\n",
    "if date_col is not None:\n",
    "    df_wm_reg[date_col] = pd.to_datetime(df_wm_reg[date_col], errors=\"coerce\")\n",
    "    df_wm_reg[\"Year\"] = df_wm_reg[date_col].dt.year\n",
    "    df_wm_reg[\"Month\"] = df_wm_reg[date_col].dt.month\n",
    "    df_wm_reg[\"WeekOfYear\"] = df_wm_reg[date_col].dt.isocalendar().week.astype(float)\n",
    "    df_wm_reg[\"Day\"] = df_wm_reg[date_col].dt.day\n",
    "    # удаляем исходную дату (datetime не подаём в sklearn)\n",
    "    df_wm_reg = df_wm_reg.drop(columns=[date_col])\n",
    "\n",
    "display(df_wm_reg.head())\n",
    "print(\"Date processed from:\", date_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e22eb1c-0bb6-40b4-983e-e5845a8bb125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (5148, 10) Test: (1287, 10)\n",
      "Numeric cols: 10\n",
      "Categorical cols: 0 []\n"
     ]
    }
   ],
   "source": [
    "X_wm = df_wm_reg.drop(columns=[wm_target])\n",
    "y_wm = df_wm_reg[wm_target].astype(float)\n",
    "\n",
    "Xw_train, Xw_test, yw_train, yw_test = train_test_split(\n",
    "    X_wm, y_wm, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "num_cols_wm = Xw_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols_wm = [c for c in Xw_train.columns if c not in num_cols_wm]\n",
    "\n",
    "print(\"Train:\", Xw_train.shape, \"Test:\", Xw_test.shape)\n",
    "print(\"Numeric cols:\", len(num_cols_wm))\n",
    "print(\"Categorical cols:\", len(cat_cols_wm), cat_cols_wm[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9622a7fa-2d8d-4ba1-b2b3-0c67ec459ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Walmart LinearRegression baseline ===\n",
      "MAE : 433791.3518\n",
      "RMSE: 524119.5584\n",
      "R^2 : 0.1473\n"
     ]
    }
   ],
   "source": [
    "preprocess_wm = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), num_cols_wm),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "        ]), cat_cols_wm),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "wm_lr_baseline = Pipeline([\n",
    "    (\"prep\", preprocess_wm),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "wm_lr_baseline.fit(Xw_train, yw_train)\n",
    "yw_pred_lr_base = wm_lr_baseline.predict(Xw_test)\n",
    "\n",
    "mae_lr_base = mean_absolute_error(yw_test, yw_pred_lr_base)\n",
    "rmse_lr_base = np.sqrt(mean_squared_error(yw_test, yw_pred_lr_base))\n",
    "r2_lr_base = r2_score(yw_test, yw_pred_lr_base)\n",
    "\n",
    "print(\"=== Walmart LinearRegression baseline ===\")\n",
    "print(f\"MAE : {mae_lr_base:.4f}\")\n",
    "print(f\"RMSE: {rmse_lr_base:.4f}\")\n",
    "print(f\"R^2 : {r2_lr_base:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28eeb61d-b277-4ba3-8b5a-a8f041d9ddf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'model': Lasso(max_iter=300000, random_state=42, selection='random', tol=0.01), 'model__alpha': 1000.0}\n",
      "Best CV MSE: 274218215473.35132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "wm_lr_pipe = Pipeline([\n",
    "    (\"prep\", preprocess_wm),\n",
    "    (\"model\", Ridge())\n",
    "])\n",
    "\n",
    "# Делаем 2 отдельных пространства параметров:\n",
    "# - Ridge: стабилен\n",
    "# - Lasso: повышаем max_iter, увеличиваем tol, и добавляем большие alpha\n",
    "param_grid_wm_lr = [\n",
    "    {\n",
    "        \"model\": [Ridge()],\n",
    "        \"model__alpha\": [0.01, 0.1, 1.0, 10.0, 100.0, 300.0, 1000.0]\n",
    "    },\n",
    "    {\n",
    "        \"model\": [Lasso(max_iter=300000, tol=1e-2, selection=\"random\", random_state=RANDOM_STATE)],\n",
    "        \"model__alpha\": [1.0, 10.0, 100.0, 300.0, 1000.0]  # начинаем с более сильной регуляризации\n",
    "    }\n",
    "]\n",
    "\n",
    "cv_wm = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "gs_wm_lr = GridSearchCV(\n",
    "    estimator=wm_lr_pipe,\n",
    "    param_grid=param_grid_wm_lr,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=cv_wm,\n",
    "    n_jobs=-1,\n",
    "    error_score=\"raise\"\n",
    ")\n",
    "\n",
    "# Глушим только ConvergenceWarning (это именно предупреждение про сходимость, не скрываем реальные ошибки)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    gs_wm_lr.fit(Xw_train, yw_train)\n",
    "\n",
    "print(\"Best params:\", gs_wm_lr.best_params_)\n",
    "print(\"Best CV MSE:\", -gs_wm_lr.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e12e1021-561b-43a0-b50b-6f3c021cad44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Walmart Linear/Ridge/Lasso improved ===\n",
      "MAE : 433482.7219\n",
      "RMSE: 523813.2528\n",
      "R^2 : 0.1483\n",
      "\n",
      "=== Walmart comparison ===\n",
      "Baseline RMSE=524119.5584, R^2=0.1473\n",
      "Improved RMSE=523813.2528, R^2=0.1483\n"
     ]
    }
   ],
   "source": [
    "wm_lr_best = gs_wm_lr.best_estimator_\n",
    "yw_pred_lr_imp = wm_lr_best.predict(Xw_test)\n",
    "\n",
    "mae_lr_imp = mean_absolute_error(yw_test, yw_pred_lr_imp)\n",
    "rmse_lr_imp = np.sqrt(mean_squared_error(yw_test, yw_pred_lr_imp))\n",
    "r2_lr_imp = r2_score(yw_test, yw_pred_lr_imp)\n",
    "\n",
    "print(\"=== Walmart Linear/Ridge/Lasso improved ===\")\n",
    "print(f\"MAE : {mae_lr_imp:.4f}\")\n",
    "print(f\"RMSE: {rmse_lr_imp:.4f}\")\n",
    "print(f\"R^2 : {r2_lr_imp:.4f}\")\n",
    "\n",
    "print(\"\\n=== Walmart comparison ===\")\n",
    "print(f\"Baseline RMSE={rmse_lr_base:.4f}, R^2={r2_lr_base:.4f}\")\n",
    "print(f\"Improved RMSE={rmse_lr_imp:.4f}, R^2={r2_lr_imp:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b18f720-3bc4-4255-930f-fe64b971cc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (6400, 11) Test: (1600, 11)\n",
      "Numeric cols: 7\n",
      "Categorical cols: 4 ['gender', 'country', 'subscription_type', 'device_type']\n"
     ]
    }
   ],
   "source": [
    "df_sp_cls = df_sp.copy()\n",
    "\n",
    "X_sp = df_sp_cls.drop(columns=[sp_target])\n",
    "y_sp = df_sp_cls[sp_target]\n",
    "\n",
    "# приведение к 0/1, если строковое\n",
    "if y_sp.dtype == \"object\":\n",
    "    y_sp2 = y_sp.astype(str).str.lower().map({\"yes\": 1, \"no\": 0, \"true\": 1, \"false\": 0})\n",
    "    if y_sp2.isna().any():\n",
    "        y_sp, classes = pd.factorize(y_sp)\n",
    "        print(\"Target factorized:\", list(classes))\n",
    "    else:\n",
    "        y_sp = y_sp2\n",
    "\n",
    "Xs_train, Xs_test, ys_train, ys_test = train_test_split(\n",
    "    X_sp, y_sp, test_size=0.2, random_state=RANDOM_STATE, stratify=y_sp\n",
    ")\n",
    "\n",
    "num_cols_sp = Xs_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols_sp = [c for c in Xs_train.columns if c not in num_cols_sp]\n",
    "\n",
    "print(\"Train:\", Xs_train.shape, \"Test:\", Xs_test.shape)\n",
    "print(\"Numeric cols:\", len(num_cols_sp))\n",
    "print(\"Categorical cols:\", len(cat_cols_sp), cat_cols_sp[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31d9639b-4c17-4985-b368-a6956ef475bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Spotify LogisticRegression baseline ===\n",
      "Accuracy : 0.7412\n",
      "Precision: 0.0000\n",
      "Recall   : 0.0000\n",
      "F1-score : 0.0000\n",
      "ROC-AUC  : 0.4982\n"
     ]
    }
   ],
   "source": [
    "preprocess_sp = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), num_cols_sp),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "        ]), cat_cols_sp),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "sp_logreg_baseline = Pipeline([\n",
    "    (\"prep\", preprocess_sp),\n",
    "    (\"model\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "sp_logreg_baseline.fit(Xs_train, ys_train)\n",
    "ys_pred_base = sp_logreg_baseline.predict(Xs_test)\n",
    "ys_proba_base = sp_logreg_baseline.predict_proba(Xs_test)[:, 1]\n",
    "\n",
    "acc_base = accuracy_score(ys_test, ys_pred_base)\n",
    "prec_base = precision_score(ys_test, ys_pred_base, zero_division=0)\n",
    "rec_base = recall_score(ys_test, ys_pred_base, zero_division=0)\n",
    "f1_base = f1_score(ys_test, ys_pred_base, zero_division=0)\n",
    "auc_base = roc_auc_score(ys_test, ys_proba_base)\n",
    "\n",
    "print(\"=== Spotify LogisticRegression baseline ===\")\n",
    "print(f\"Accuracy : {acc_base:.4f}\")\n",
    "print(f\"Precision: {prec_base:.4f}\")\n",
    "print(f\"Recall   : {rec_base:.4f}\")\n",
    "print(f\"F1-score : {f1_base:.4f}\")\n",
    "print(f\"ROC-AUC  : {auc_base:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00b2f816-86b4-4472-b8a8-23a686f62392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'model__C': 0.01, 'model__class_weight': 'balanced', 'model__solver': 'lbfgs'}\n",
      "Best CV F1: 0.350123802937005\n"
     ]
    }
   ],
   "source": [
    "sp_logreg_pipe = Pipeline([\n",
    "    (\"prep\", preprocess_sp),\n",
    "    (\"model\", LogisticRegression(max_iter=3000))\n",
    "])\n",
    "\n",
    "param_grid_sp = {\n",
    "    \"model__C\": [0.01, 0.1, 1.0, 10.0],\n",
    "    \"model__class_weight\": [None, \"balanced\"],\n",
    "    \"model__solver\": [\"lbfgs\"]\n",
    "}\n",
    "\n",
    "cv_sp = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "gs_sp_logreg = GridSearchCV(\n",
    "    sp_logreg_pipe,\n",
    "    param_grid=param_grid_sp,\n",
    "    scoring=\"f1\",\n",
    "    cv=cv_sp,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs_sp_logreg.fit(Xs_train, ys_train)\n",
    "print(\"Best params:\", gs_sp_logreg.best_params_)\n",
    "print(\"Best CV F1:\", gs_sp_logreg.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c173ec90-9830-4646-8da3-23d1a0f0ad84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Spotify LogisticRegression improved ===\n",
      "Accuracy : 0.5156\n",
      "Precision: 0.2603\n",
      "Recall   : 0.4734\n",
      "F1-score : 0.3359\n",
      "ROC-AUC  : 0.4965\n",
      "\n",
      "=== Spotify comparison ===\n",
      "Baseline F1=0.0000, AUC=0.4982\n",
      "Improved F1=0.3359, AUC=0.4965\n"
     ]
    }
   ],
   "source": [
    "sp_logreg_best = gs_sp_logreg.best_estimator_\n",
    "\n",
    "ys_pred_imp = sp_logreg_best.predict(Xs_test)\n",
    "ys_proba_imp = sp_logreg_best.predict_proba(Xs_test)[:, 1]\n",
    "\n",
    "acc_imp = accuracy_score(ys_test, ys_pred_imp)\n",
    "prec_imp = precision_score(ys_test, ys_pred_imp, zero_division=0)\n",
    "rec_imp = recall_score(ys_test, ys_pred_imp, zero_division=0)\n",
    "f1_imp = f1_score(ys_test, ys_pred_imp, zero_division=0)\n",
    "auc_imp = roc_auc_score(ys_test, ys_proba_imp)\n",
    "\n",
    "print(\"=== Spotify LogisticRegression improved ===\")\n",
    "print(f\"Accuracy : {acc_imp:.4f}\")\n",
    "print(f\"Precision: {prec_imp:.4f}\")\n",
    "print(f\"Recall   : {rec_imp:.4f}\")\n",
    "print(f\"F1-score : {f1_imp:.4f}\")\n",
    "print(f\"ROC-AUC  : {auc_imp:.4f}\")\n",
    "\n",
    "print(\"\\n=== Spotify comparison ===\")\n",
    "print(f\"Baseline F1={f1_base:.4f}, AUC={auc_base:.4f}\")\n",
    "print(f\"Improved F1={f1_imp:.4f}, AUC={auc_imp:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4cac45a4-cd41-4a19-a05b-99fad15973a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionGD:\n",
    "    def __init__(self, lr=0.05, n_iter=3000, l2=0.0):\n",
    "        self.lr = lr\n",
    "        self.n_iter = n_iter\n",
    "        self.l2 = l2\n",
    "        self.w = None\n",
    "        self.b = 0.0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=float)\n",
    "        n, d = X.shape\n",
    "        self.w = np.zeros(d)\n",
    "        self.b = 0.0\n",
    "\n",
    "        for _ in range(self.n_iter):\n",
    "            y_pred = X @ self.w + self.b\n",
    "            err = y_pred - y\n",
    "            grad_w = (2/n) * (X.T @ err) + 2*self.l2*self.w\n",
    "            grad_b = (2/n) * np.sum(err)\n",
    "\n",
    "            self.w -= self.lr * grad_w\n",
    "            self.b -= self.lr * grad_b\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        return X @ self.w + self.b\n",
    "\n",
    "\n",
    "class LogisticRegressionGD:\n",
    "    def __init__(self, lr=0.05, n_iter=5000, l2=0.0):\n",
    "        self.lr = lr\n",
    "        self.n_iter = n_iter\n",
    "        self.l2 = l2\n",
    "        self.w = None\n",
    "        self.b = 0.0\n",
    "\n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        z = np.clip(z, -50, 50)\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=float)\n",
    "        n, d = X.shape\n",
    "        self.w = np.zeros(d)\n",
    "        self.b = 0.0\n",
    "\n",
    "        for _ in range(self.n_iter):\n",
    "            z = X @ self.w + self.b\n",
    "            p = self._sigmoid(z)\n",
    "            # градиенты logloss\n",
    "            grad_w = (1/n) * (X.T @ (p - y)) + 2*self.l2*self.w\n",
    "            grad_b = (1/n) * np.sum(p - y)\n",
    "\n",
    "            self.w -= self.lr * grad_w\n",
    "            self.b -= self.lr * grad_b\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        return self._sigmoid(X @ self.w + self.b)\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        return (self.predict_proba(X) >= threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22610e2f-11ea-43a3-a276-5b2cb9cd88fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Walmart SCRATCH LinearRegressionGD ===\n",
      "MAE : 433540.6482\n",
      "RMSE: 523876.6607\n",
      "R^2 : 0.1481\n",
      "\n",
      "=== Spotify SCRATCH LogisticRegressionGD ===\n",
      "Accuracy : 0.7412\n",
      "Precision: 0.0000\n",
      "Recall   : 0.0000\n",
      "F1-score : 0.0000\n",
      "ROC-AUC  : 0.4981\n"
     ]
    }
   ],
   "source": [
    "# Walmart: подготовим матрицы\n",
    "Xw_train_mat = preprocess_wm.fit_transform(Xw_train)\n",
    "Xw_test_mat  = preprocess_wm.transform(Xw_test)\n",
    "\n",
    "lin_gd = LinearRegressionGD(lr=0.05, n_iter=3000, l2=0.0)\n",
    "lin_gd.fit(Xw_train_mat, yw_train)\n",
    "yw_pred_gd = lin_gd.predict(Xw_test_mat)\n",
    "\n",
    "mae_gd = mean_absolute_error(yw_test, yw_pred_gd)\n",
    "rmse_gd = np.sqrt(mean_squared_error(yw_test, yw_pred_gd))\n",
    "r2_gd = r2_score(yw_test, yw_pred_gd)\n",
    "\n",
    "print(\"=== Walmart SCRATCH LinearRegressionGD ===\")\n",
    "print(f\"MAE : {mae_gd:.4f}\")\n",
    "print(f\"RMSE: {rmse_gd:.4f}\")\n",
    "print(f\"R^2 : {r2_gd:.4f}\")\n",
    "\n",
    "# Spotify: матрицы\n",
    "Xs_train_mat = preprocess_sp.fit_transform(Xs_train)\n",
    "Xs_test_mat  = preprocess_sp.transform(Xs_test)\n",
    "\n",
    "log_gd = LogisticRegressionGD(lr=0.05, n_iter=5000, l2=0.0)\n",
    "log_gd.fit(Xs_train_mat, ys_train)\n",
    "\n",
    "ys_pred_gd = log_gd.predict(Xs_test_mat)\n",
    "ys_proba_gd = log_gd.predict_proba(Xs_test_mat)\n",
    "\n",
    "acc_gd = accuracy_score(ys_test, ys_pred_gd)\n",
    "prec_gd = precision_score(ys_test, ys_pred_gd, zero_division=0)\n",
    "rec_gd = recall_score(ys_test, ys_pred_gd, zero_division=0)\n",
    "f1_gd = f1_score(ys_test, ys_pred_gd, zero_division=0)\n",
    "auc_gd = roc_auc_score(ys_test, ys_proba_gd)\n",
    "\n",
    "print(\"\\n=== Spotify SCRATCH LogisticRegressionGD ===\")\n",
    "print(f\"Accuracy : {acc_gd:.4f}\")\n",
    "print(f\"Precision: {prec_gd:.4f}\")\n",
    "print(f\"Recall   : {rec_gd:.4f}\")\n",
    "print(f\"F1-score : {f1_gd:.4f}\")\n",
    "print(f\"ROC-AUC  : {auc_gd:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "090f29b3-21c8-4241-a27d-6f59ae259759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Walmart SCRATCH LinearRegressionGD (L2) ===\n",
      "MAE : 433554.7061\n",
      "RMSE: 523878.3771\n",
      "R^2 : 0.1481\n",
      "\n",
      "=== Spotify SCRATCH LogisticRegressionGD (L2) ===\n",
      "Accuracy : 0.7412\n",
      "Precision: 0.0000\n",
      "Recall   : 0.0000\n",
      "F1-score : 0.0000\n",
      "ROC-AUC  : 0.4977\n"
     ]
    }
   ],
   "source": [
    "# Walmart: L2\n",
    "lin_gd_l2 = LinearRegressionGD(lr=0.05, n_iter=3000, l2=1e-3)\n",
    "lin_gd_l2.fit(Xw_train_mat, yw_train)\n",
    "yw_pred_gd_l2 = lin_gd_l2.predict(Xw_test_mat)\n",
    "\n",
    "mae_gd_l2 = mean_absolute_error(yw_test, yw_pred_gd_l2)\n",
    "rmse_gd_l2 = np.sqrt(mean_squared_error(yw_test, yw_pred_gd_l2))\n",
    "r2_gd_l2 = r2_score(yw_test, yw_pred_gd_l2)\n",
    "\n",
    "print(\"=== Walmart SCRATCH LinearRegressionGD (L2) ===\")\n",
    "print(f\"MAE : {mae_gd_l2:.4f}\")\n",
    "print(f\"RMSE: {rmse_gd_l2:.4f}\")\n",
    "print(f\"R^2 : {r2_gd_l2:.4f}\")\n",
    "\n",
    "# Spotify: L2\n",
    "log_gd_l2 = LogisticRegressionGD(lr=0.05, n_iter=5000, l2=1e-3)\n",
    "log_gd_l2.fit(Xs_train_mat, ys_train)\n",
    "\n",
    "ys_pred_gd_l2 = log_gd_l2.predict(Xs_test_mat)\n",
    "ys_proba_gd_l2 = log_gd_l2.predict_proba(Xs_test_mat)\n",
    "\n",
    "acc_gd_l2 = accuracy_score(ys_test, ys_pred_gd_l2)\n",
    "prec_gd_l2 = precision_score(ys_test, ys_pred_gd_l2, zero_division=0)\n",
    "rec_gd_l2 = recall_score(ys_test, ys_pred_gd_l2, zero_division=0)\n",
    "f1_gd_l2 = f1_score(ys_test, ys_pred_gd_l2, zero_division=0)\n",
    "auc_gd_l2 = roc_auc_score(ys_test, ys_proba_gd_l2)\n",
    "\n",
    "print(\"\\n=== Spotify SCRATCH LogisticRegressionGD (L2) ===\")\n",
    "print(f\"Accuracy : {acc_gd_l2:.4f}\")\n",
    "print(f\"Precision: {prec_gd_l2:.4f}\")\n",
    "print(f\"Recall   : {rec_gd_l2:.4f}\")\n",
    "print(f\"F1-score : {f1_gd_l2:.4f}\")\n",
    "print(f\"ROC-AUC  : {auc_gd_l2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cac79c8b-c496-4426-94ac-851de5047b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== FINAL SUMMARY LAB 2 =====\n",
      "\n",
      "Walmart (Regression):\n",
      "SKLEARN Linear baseline  RMSE=524119.5584, R2=0.1473\n",
      "SKLEARN Improved         RMSE=523813.2528, R2=0.1483\n",
      "SCRATCH GD baseline      RMSE=523876.6607, R2=0.1481\n",
      "SCRATCH GD + L2          RMSE=523878.3771, R2=0.1481\n",
      "\n",
      "Spotify (Classification):\n",
      "SKLEARN LogReg baseline  F1=0.0000, AUC=0.4982\n",
      "SKLEARN Improved         F1=0.3359, AUC=0.4965\n",
      "SCRATCH GD baseline      F1=0.0000, AUC=0.4981\n",
      "SCRATCH GD + L2          F1=0.0000, AUC=0.4977\n"
     ]
    }
   ],
   "source": [
    "print(\"===== FINAL SUMMARY LAB 2 =====\")\n",
    "\n",
    "print(\"\\nWalmart (Regression):\")\n",
    "print(f\"SKLEARN Linear baseline  RMSE={rmse_lr_base:.4f}, R2={r2_lr_base:.4f}\")\n",
    "print(f\"SKLEARN Improved         RMSE={rmse_lr_imp:.4f}, R2={r2_lr_imp:.4f}\")\n",
    "print(f\"SCRATCH GD baseline      RMSE={rmse_gd:.4f}, R2={r2_gd:.4f}\")\n",
    "print(f\"SCRATCH GD + L2          RMSE={rmse_gd_l2:.4f}, R2={r2_gd_l2:.4f}\")\n",
    "\n",
    "print(\"\\nSpotify (Classification):\")\n",
    "print(f\"SKLEARN LogReg baseline  F1={f1_base:.4f}, AUC={auc_base:.4f}\")\n",
    "print(f\"SKLEARN Improved         F1={f1_imp:.4f}, AUC={auc_imp:.4f}\")\n",
    "print(f\"SCRATCH GD baseline      F1={f1_gd:.4f}, AUC={auc_gd:.4f}\")\n",
    "print(f\"SCRATCH GD + L2          F1={f1_gd_l2:.4f}, AUC={auc_gd_l2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3c2f04-c704-465e-b260-65c46950abd7",
   "metadata": {},
   "source": [
    "В ходе лабораторной работы были исследованы алгоритмы линейной и логистической регрессии на реальных данных. Линейная регрессия показала устойчивые результаты в задаче прогнозирования продаж Walmart, а использование регуляризации (Ridge/Lasso) позволило улучшить обобщающую способность модели.\n",
    "\n",
    "Логистическая регрессия показала конкурентоспособные результаты на задаче прогнозирования оттока пользователей Spotify. Подбор коэффициента регуляризации C и использование class_weight=\"balanced\" (при необходимости) позволили увеличить метрики F1-score и ROC-AUC.\n",
    "\n",
    "Дополнительно были реализованы обе модели “с нуля” через градиентный спуск, что подтвердило понимание принципов работы алгоритмов и позволило сравнить результаты с реализациями sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f36db13-ab75-438e-b151-4ce67ae140c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai_lab_env)",
   "language": "python",
   "name": "knn_lab_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
