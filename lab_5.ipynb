{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e35b8b9-44bf-45d4-a344-acfadec47a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 140)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39982251-c04e-4a28-a17d-257a0bfa0ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walmart: (6435, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>05-02-2010</td>\n",
       "      <td>1643690.90</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12-02-2010</td>\n",
       "      <td>1641957.44</td>\n",
       "      <td>1</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>211.242170</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19-02-2010</td>\n",
       "      <td>1611968.17</td>\n",
       "      <td>0</td>\n",
       "      <td>39.93</td>\n",
       "      <td>2.514</td>\n",
       "      <td>211.289143</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>26-02-2010</td>\n",
       "      <td>1409727.59</td>\n",
       "      <td>0</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2.561</td>\n",
       "      <td>211.319643</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>05-03-2010</td>\n",
       "      <td>1554806.68</td>\n",
       "      <td>0</td>\n",
       "      <td>46.50</td>\n",
       "      <td>2.625</td>\n",
       "      <td>211.350143</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store        Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price         CPI  Unemployment\n",
       "0      1  05-02-2010    1643690.90             0        42.31       2.572  211.096358         8.106\n",
       "1      1  12-02-2010    1641957.44             1        38.51       2.548  211.242170         8.106\n",
       "2      1  19-02-2010    1611968.17             0        39.93       2.514  211.289143         8.106\n",
       "3      1  26-02-2010    1409727.59             0        46.63       2.561  211.319643         8.106\n",
       "4      1  05-03-2010    1554806.68             0        46.50       2.625  211.350143         8.106"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spotify: (8000, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>subscription_type</th>\n",
       "      <th>listening_time</th>\n",
       "      <th>songs_played_per_day</th>\n",
       "      <th>skip_rate</th>\n",
       "      <th>device_type</th>\n",
       "      <th>ads_listened_per_week</th>\n",
       "      <th>offline_listening</th>\n",
       "      <th>is_churned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>54</td>\n",
       "      <td>CA</td>\n",
       "      <td>Free</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>0.20</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>33</td>\n",
       "      <td>DE</td>\n",
       "      <td>Family</td>\n",
       "      <td>141</td>\n",
       "      <td>62</td>\n",
       "      <td>0.34</td>\n",
       "      <td>Web</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>AU</td>\n",
       "      <td>Premium</td>\n",
       "      <td>199</td>\n",
       "      <td>38</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>CA</td>\n",
       "      <td>Student</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Other</td>\n",
       "      <td>29</td>\n",
       "      <td>US</td>\n",
       "      <td>Family</td>\n",
       "      <td>250</td>\n",
       "      <td>57</td>\n",
       "      <td>0.36</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  gender  age country subscription_type  listening_time  songs_played_per_day  skip_rate device_type  ads_listened_per_week  \\\n",
       "0        1  Female   54      CA              Free              26                    23       0.20     Desktop                     31   \n",
       "1        2   Other   33      DE            Family             141                    62       0.34         Web                      0   \n",
       "2        3    Male   38      AU           Premium             199                    38       0.04      Mobile                      0   \n",
       "3        4  Female   22      CA           Student              36                     2       0.31      Mobile                      0   \n",
       "4        5   Other   29      US            Family             250                    57       0.36      Mobile                      0   \n",
       "\n",
       "   offline_listening  is_churned  \n",
       "0                  0           1  \n",
       "1                  1           0  \n",
       "2                  1           1  \n",
       "3                  1           0  \n",
       "4                  1           1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "walmart_path = \"dataset/Walmart_Sales.csv\"\n",
    "spotify_path = \"dataset/spotify_churn_dataset.csv\"\n",
    "\n",
    "df_wm = pd.read_csv(walmart_path)\n",
    "df_sp = pd.read_csv(spotify_path)\n",
    "\n",
    "print(\"Walmart:\", df_wm.shape)\n",
    "display(df_wm.head())\n",
    "\n",
    "print(\"\\nSpotify:\", df_sp.shape)\n",
    "display(df_sp.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8406da24-8a89-40ce-8f63-45bec17900c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Walmart target: Weekly_Sales\n",
      "Detected Spotify target: is_churned\n"
     ]
    }
   ],
   "source": [
    "wm_target_candidates = [\"Weekly_Sales\", \"weekly_sales\", \"Sales\", \"sales\", \"Target\", \"target\"]\n",
    "wm_target = next((c for c in wm_target_candidates if c in df_wm.columns), None)\n",
    "\n",
    "sp_target_candidates = [\"churn\", \"Churn\", \"is_churn\", \"IsChurn\", \"label\", \"Label\", \"target\", \"Target\", \"y\", \"is_churned\"]\n",
    "sp_target = next((c for c in sp_target_candidates if c in df_sp.columns), None)\n",
    "\n",
    "print(\"Detected Walmart target:\", wm_target)\n",
    "print(\"Detected Spotify target:\", sp_target)\n",
    "\n",
    "if wm_target is None:\n",
    "    raise ValueError(\"Не нашёл target в Walmart_Sales.csv. Укажи wm_target вручную.\")\n",
    "if sp_target is None:\n",
    "    raise ValueError(\"Не нашёл target в spotify_churn_dataset.csv. Укажи sp_target вручную.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6bc1108-5c6f-4926-9239-ceb3e390ccd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (5148, 10) Test: (1287, 10)\n",
      "Numeric: 10 Categorical: 0 []\n"
     ]
    }
   ],
   "source": [
    "df_wm_reg = df_wm.copy()\n",
    "\n",
    "date_col_candidates = [\"Date\", \"date\", \"DATE\"]\n",
    "date_col = next((c for c in date_col_candidates if c in df_wm_reg.columns), None)\n",
    "\n",
    "if date_col is not None:\n",
    "    df_wm_reg[date_col] = pd.to_datetime(df_wm_reg[date_col], errors=\"coerce\")\n",
    "    df_wm_reg[\"Year\"] = df_wm_reg[date_col].dt.year\n",
    "    df_wm_reg[\"Month\"] = df_wm_reg[date_col].dt.month\n",
    "    df_wm_reg[\"WeekOfYear\"] = df_wm_reg[date_col].dt.isocalendar().week.astype(float)\n",
    "    df_wm_reg[\"Day\"] = df_wm_reg[date_col].dt.day\n",
    "    df_wm_reg = df_wm_reg.drop(columns=[date_col])\n",
    "\n",
    "X_wm = df_wm_reg.drop(columns=[wm_target])\n",
    "y_wm = df_wm_reg[wm_target].astype(float)\n",
    "\n",
    "Xw_train, Xw_test, yw_train, yw_test = train_test_split(\n",
    "    X_wm, y_wm, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "num_cols_wm = Xw_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols_wm = [c for c in Xw_train.columns if c not in num_cols_wm]\n",
    "\n",
    "print(\"Train:\", Xw_train.shape, \"Test:\", Xw_test.shape)\n",
    "print(\"Numeric:\", len(num_cols_wm), \"Categorical:\", len(cat_cols_wm), cat_cols_wm[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3d726e5-1f2e-417b-a693-93541265d2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Walmart GradientBoostingRegressor baseline ===\n",
      "MAE : 133825.6988\n",
      "RMSE: 194819.0911\n",
      "R^2 : 0.8822\n"
     ]
    }
   ],
   "source": [
    "preprocess_wm = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))]), num_cols_wm),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "        ]), cat_cols_wm),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "wm_gb_base = Pipeline([\n",
    "    (\"prep\", preprocess_wm),\n",
    "    (\"model\", GradientBoostingRegressor(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "wm_gb_base.fit(Xw_train, yw_train)\n",
    "yw_pred_gb_base = wm_gb_base.predict(Xw_test)\n",
    "\n",
    "mae_gb_base = mean_absolute_error(yw_test, yw_pred_gb_base)\n",
    "rmse_gb_base = np.sqrt(mean_squared_error(yw_test, yw_pred_gb_base))\n",
    "r2_gb_base = r2_score(yw_test, yw_pred_gb_base)\n",
    "\n",
    "print(\"=== Walmart GradientBoostingRegressor baseline ===\")\n",
    "print(f\"MAE : {mae_gb_base:.4f}\")\n",
    "print(f\"RMSE: {rmse_gb_base:.4f}\")\n",
    "print(f\"R^2 : {r2_gb_base:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "420a5acf-4c59-4515-b6f4-a80a4857e230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__n_estimators': 400, 'model__subsample': 1.0}\n",
      "Best CV MSE: 14335824872.376583\n"
     ]
    }
   ],
   "source": [
    "wm_gb_pipe = Pipeline([\n",
    "    (\"prep\", preprocess_wm),\n",
    "    (\"model\", GradientBoostingRegressor(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "param_grid_wm_gb = {\n",
    "    \"model__n_estimators\": [200, 400],\n",
    "    \"model__learning_rate\": [0.03, 0.1],\n",
    "    \"model__max_depth\": [2, 3, 5],\n",
    "    \"model__subsample\": [0.7, 1.0]\n",
    "}\n",
    "\n",
    "cv_wm = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "gs_wm_gb = GridSearchCV(\n",
    "    estimator=wm_gb_pipe,\n",
    "    param_grid=param_grid_wm_gb,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=cv_wm,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs_wm_gb.fit(Xw_train, yw_train)\n",
    "print(\"Best params:\", gs_wm_gb.best_params_)\n",
    "print(\"Best CV MSE:\", -gs_wm_gb.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9def5cc-ec15-4fb1-bca0-3a50ca911354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Walmart GradientBoostingRegressor improved ===\n",
      "MAE : 63182.0978\n",
      "RMSE: 118855.8977\n",
      "R^2 : 0.9561\n",
      "\n",
      "=== Walmart comparison ===\n",
      "Baseline RMSE=194819.0911, R^2=0.8822\n",
      "Improved RMSE=118855.8977, R^2=0.9561\n"
     ]
    }
   ],
   "source": [
    "wm_gb_best = gs_wm_gb.best_estimator_\n",
    "yw_pred_gb_imp = wm_gb_best.predict(Xw_test)\n",
    "\n",
    "mae_gb_imp = mean_absolute_error(yw_test, yw_pred_gb_imp)\n",
    "rmse_gb_imp = np.sqrt(mean_squared_error(yw_test, yw_pred_gb_imp))\n",
    "r2_gb_imp = r2_score(yw_test, yw_pred_gb_imp)\n",
    "\n",
    "print(\"=== Walmart GradientBoostingRegressor improved ===\")\n",
    "print(f\"MAE : {mae_gb_imp:.4f}\")\n",
    "print(f\"RMSE: {rmse_gb_imp:.4f}\")\n",
    "print(f\"R^2 : {r2_gb_imp:.4f}\")\n",
    "\n",
    "print(\"\\n=== Walmart comparison ===\")\n",
    "print(f\"Baseline RMSE={rmse_gb_base:.4f}, R^2={r2_gb_base:.4f}\")\n",
    "print(f\"Improved RMSE={rmse_gb_imp:.4f}, R^2={r2_gb_imp:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebf28e76-c1db-4b97-8f15-cd872213a3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (6400, 11) Test: (1600, 11)\n",
      "Numeric: 7 Categorical: 4 ['gender', 'country', 'subscription_type', 'device_type']\n"
     ]
    }
   ],
   "source": [
    "X_sp = df_sp.drop(columns=[sp_target])\n",
    "y_sp = df_sp[sp_target]\n",
    "\n",
    "if y_sp.dtype == \"object\":\n",
    "    y_map = y_sp.astype(str).str.lower().map({\"yes\": 1, \"no\": 0, \"true\": 1, \"false\": 0})\n",
    "    if y_map.isna().any():\n",
    "        y_sp, classes = pd.factorize(y_sp)\n",
    "        print(\"Target factorized:\", list(classes))\n",
    "    else:\n",
    "        y_sp = y_map\n",
    "\n",
    "Xs_train, Xs_test, ys_train, ys_test = train_test_split(\n",
    "    X_sp, y_sp, test_size=0.2, random_state=RANDOM_STATE, stratify=y_sp\n",
    ")\n",
    "\n",
    "num_cols_sp = Xs_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols_sp = [c for c in Xs_train.columns if c not in num_cols_sp]\n",
    "\n",
    "print(\"Train:\", Xs_train.shape, \"Test:\", Xs_test.shape)\n",
    "print(\"Numeric:\", len(num_cols_sp), \"Categorical:\", len(cat_cols_sp), cat_cols_sp[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38ef5837-5d3f-47e6-8c6c-ebed5760922e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Spotify GradientBoostingClassifier baseline ===\n",
      "Accuracy : 0.7388\n",
      "Precision: 0.1667\n",
      "Recall   : 0.0024\n",
      "F1-score : 0.0048\n",
      "ROC-AUC  : 0.5018\n"
     ]
    }
   ],
   "source": [
    "preprocess_sp = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))]), num_cols_sp),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "        ]), cat_cols_sp),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "sp_gb_base = Pipeline([\n",
    "    (\"prep\", preprocess_sp),\n",
    "    (\"model\", GradientBoostingClassifier(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "sp_gb_base.fit(Xs_train, ys_train)\n",
    "ys_pred_base = sp_gb_base.predict(Xs_test)\n",
    "ys_proba_base = sp_gb_base.predict_proba(Xs_test)[:, 1]\n",
    "\n",
    "acc_base = accuracy_score(ys_test, ys_pred_base)\n",
    "prec_base = precision_score(ys_test, ys_pred_base, zero_division=0)\n",
    "rec_base = recall_score(ys_test, ys_pred_base, zero_division=0)\n",
    "f1_base = f1_score(ys_test, ys_pred_base, zero_division=0)\n",
    "auc_base = roc_auc_score(ys_test, ys_proba_base)\n",
    "\n",
    "print(\"=== Spotify GradientBoostingClassifier baseline ===\")\n",
    "print(f\"Accuracy : {acc_base:.4f}\")\n",
    "print(f\"Precision: {prec_base:.4f}\")\n",
    "print(f\"Recall   : {rec_base:.4f}\")\n",
    "print(f\"F1-score : {f1_base:.4f}\")\n",
    "print(f\"ROC-AUC  : {auc_base:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1ca038-4636-4266-a6f1-a9a7da40ed46",
   "metadata": {},
   "source": [
    "Гипотезы:\n",
    "\n",
    "больше деревьев и меньший learning_rate обычно дают лучший результат\n",
    "\n",
    "subsample < 1 снижает переобучение\n",
    "\n",
    "глубина слабых деревьев регулирует сложность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec1ce036-76b4-4c35-9488-b4980dff34a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 400, 'model__subsample': 0.7}\n",
      "Best CV F1: 0.05944242580834082\n"
     ]
    }
   ],
   "source": [
    "sp_gb_pipe = Pipeline([\n",
    "    (\"prep\", preprocess_sp),\n",
    "    (\"model\", GradientBoostingClassifier(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "param_grid_sp_gb = {\n",
    "    \"model__n_estimators\": [200, 400],\n",
    "    \"model__learning_rate\": [0.03, 0.1],\n",
    "    \"model__max_depth\": [2, 3],\n",
    "    \"model__subsample\": [0.7, 1.0]\n",
    "}\n",
    "\n",
    "cv_sp = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "gs_sp_gb = GridSearchCV(\n",
    "    estimator=sp_gb_pipe,\n",
    "    param_grid=param_grid_sp_gb,\n",
    "    scoring=\"f1\",\n",
    "    cv=cv_sp,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs_sp_gb.fit(Xs_train, ys_train)\n",
    "print(\"Best params:\", gs_sp_gb.best_params_)\n",
    "print(\"Best CV F1:\", gs_sp_gb.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb3e3519-9fd3-41f7-8cdd-e7a74c682158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Spotify GradientBoostingClassifier improved ===\n",
      "Accuracy : 0.7281\n",
      "Precision: 0.2162\n",
      "Recall   : 0.0193\n",
      "F1-score : 0.0355\n",
      "ROC-AUC  : 0.5026\n",
      "\n",
      "=== Spotify comparison ===\n",
      "Baseline F1=0.0048, AUC=0.5018\n",
      "Improved F1=0.0355, AUC=0.5026\n"
     ]
    }
   ],
   "source": [
    "sp_gb_best = gs_sp_gb.best_estimator_\n",
    "\n",
    "ys_pred_imp = sp_gb_best.predict(Xs_test)\n",
    "ys_proba_imp = sp_gb_best.predict_proba(Xs_test)[:, 1]\n",
    "\n",
    "acc_imp = accuracy_score(ys_test, ys_pred_imp)\n",
    "prec_imp = precision_score(ys_test, ys_pred_imp, zero_division=0)\n",
    "rec_imp = recall_score(ys_test, ys_pred_imp, zero_division=0)\n",
    "f1_imp = f1_score(ys_test, ys_pred_imp, zero_division=0)\n",
    "auc_imp = roc_auc_score(ys_test, ys_proba_imp)\n",
    "\n",
    "print(\"=== Spotify GradientBoostingClassifier improved ===\")\n",
    "print(f\"Accuracy : {acc_imp:.4f}\")\n",
    "print(f\"Precision: {prec_imp:.4f}\")\n",
    "print(f\"Recall   : {rec_imp:.4f}\")\n",
    "print(f\"F1-score : {f1_imp:.4f}\")\n",
    "print(f\"ROC-AUC  : {auc_imp:.4f}\")\n",
    "\n",
    "print(\"\\n=== Spotify comparison ===\")\n",
    "print(f\"Baseline F1={f1_base:.4f}, AUC={auc_base:.4f}\")\n",
    "print(f\"Improved F1={f1_imp:.4f}, AUC={auc_imp:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12d272ca-f7b3-4329-98bf-bcb9e1a688de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoostingRegressorScratch:\n",
    "    def __init__(self, n_estimators=200, learning_rate=0.1, max_depth=2, random_state=42):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "        self.init_ = 0.0\n",
    "        self.models_ = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=float)\n",
    "\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "\n",
    "        self.init_ = float(np.mean(y))\n",
    "        pred = np.full_like(y, self.init_, dtype=float)\n",
    "        self.models_ = []\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            residual = y - pred\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth, random_state=rng.randint(0, 10**9))\n",
    "            tree.fit(X, residual)\n",
    "            update = tree.predict(X)\n",
    "            pred += self.learning_rate * update\n",
    "            self.models_.append(tree)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        pred = np.full(X.shape[0], self.init_, dtype=float)\n",
    "        for tree in self.models_:\n",
    "            pred += self.learning_rate * tree.predict(X)\n",
    "        return pred\n",
    "\n",
    "\n",
    "class GradientBoostingClassifierScratch:\n",
    "    def __init__(self, n_estimators=200, learning_rate=0.1, max_depth=2, random_state=42):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "        self.init_logit_ = 0.0\n",
    "        self.models_ = []\n",
    "\n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        z = np.clip(z, -50, 50)\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=float)\n",
    "\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "\n",
    "        # init logit = log(p/(1-p))\n",
    "        p0 = np.clip(np.mean(y), 1e-6, 1 - 1e-6)\n",
    "        self.init_logit_ = float(np.log(p0 / (1 - p0)))\n",
    "\n",
    "        logit = np.full(X.shape[0], self.init_logit_, dtype=float)\n",
    "        self.models_ = []\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            p = self._sigmoid(logit)\n",
    "            # псевдо-градиент для logloss: (y - p)\n",
    "            grad = y - p\n",
    "\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth, random_state=rng.randint(0, 10**9))\n",
    "            tree.fit(X, grad)\n",
    "            update = tree.predict(X)\n",
    "\n",
    "            logit += self.learning_rate * update\n",
    "            self.models_.append(tree)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        logit = np.full(X.shape[0], self.init_logit_, dtype=float)\n",
    "        for tree in self.models_:\n",
    "            logit += self.learning_rate * tree.predict(X)\n",
    "        return self._sigmoid(logit)\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        return (self.predict_proba(X) >= threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1db27a4b-ac1f-4323-88d6-a69a69ce970b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Walmart SCRATCH GB baseline ===\n",
      "RMSE: 202291.4567\n",
      "R^2 : 0.8730\n",
      "\n",
      "=== Spotify SCRATCH GB baseline ===\n",
      "F1 : 0.0000\n",
      "AUC: 0.4779\n"
     ]
    }
   ],
   "source": [
    "# Walmart scratch\n",
    "Xw_train_mat = preprocess_wm.fit_transform(Xw_train)\n",
    "Xw_test_mat  = preprocess_wm.transform(Xw_test)\n",
    "\n",
    "gb_s_reg = GradientBoostingRegressorScratch(n_estimators=200, learning_rate=0.1, max_depth=2, random_state=RANDOM_STATE)\n",
    "gb_s_reg.fit(Xw_train_mat, yw_train)\n",
    "yw_pred_s_base = gb_s_reg.predict(Xw_test_mat)\n",
    "\n",
    "rmse_s_base = np.sqrt(mean_squared_error(yw_test, yw_pred_s_base))\n",
    "r2_s_base = r2_score(yw_test, yw_pred_s_base)\n",
    "\n",
    "print(\"=== Walmart SCRATCH GB baseline ===\")\n",
    "print(f\"RMSE: {rmse_s_base:.4f}\")\n",
    "print(f\"R^2 : {r2_s_base:.4f}\")\n",
    "\n",
    "# Spotify scratch\n",
    "Xs_train_mat = preprocess_sp.fit_transform(Xs_train)\n",
    "Xs_test_mat  = preprocess_sp.transform(Xs_test)\n",
    "\n",
    "gb_s_cls = GradientBoostingClassifierScratch(n_estimators=250, learning_rate=0.1, max_depth=2, random_state=RANDOM_STATE)\n",
    "gb_s_cls.fit(Xs_train_mat, ys_train)\n",
    "\n",
    "ys_pred_s_base = gb_s_cls.predict(Xs_test_mat)\n",
    "ys_proba_s_base = gb_s_cls.predict_proba(Xs_test_mat)\n",
    "\n",
    "f1_s_base = f1_score(ys_test, ys_pred_s_base, zero_division=0)\n",
    "auc_s_base = roc_auc_score(ys_test, ys_proba_s_base)\n",
    "\n",
    "print(\"\\n=== Spotify SCRATCH GB baseline ===\")\n",
    "print(f\"F1 : {f1_s_base:.4f}\")\n",
    "print(f\"AUC: {auc_s_base:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6413be85-5473-4495-a2e0-2bf8f2f6d971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Walmart SCRATCH GB improved ===\n",
      "RMSE: 147868.8385\n",
      "R^2 : 0.9321\n",
      "\n",
      "=== Spotify SCRATCH GB improved ===\n",
      "F1 : 0.0000\n",
      "AUC: 0.4917\n"
     ]
    }
   ],
   "source": [
    "# Walmart scratch improved\n",
    "gb_s_reg2 = GradientBoostingRegressorScratch(n_estimators=500, learning_rate=0.05, max_depth=3, random_state=RANDOM_STATE)\n",
    "gb_s_reg2.fit(Xw_train_mat, yw_train)\n",
    "yw_pred_s_imp = gb_s_reg2.predict(Xw_test_mat)\n",
    "\n",
    "rmse_s_imp = np.sqrt(mean_squared_error(yw_test, yw_pred_s_imp))\n",
    "r2_s_imp = r2_score(yw_test, yw_pred_s_imp)\n",
    "\n",
    "print(\"=== Walmart SCRATCH GB improved ===\")\n",
    "print(f\"RMSE: {rmse_s_imp:.4f}\")\n",
    "print(f\"R^2 : {r2_s_imp:.4f}\")\n",
    "\n",
    "# Spotify scratch improved\n",
    "gb_s_cls2 = GradientBoostingClassifierScratch(n_estimators=600, learning_rate=0.05, max_depth=3, random_state=RANDOM_STATE)\n",
    "gb_s_cls2.fit(Xs_train_mat, ys_train)\n",
    "\n",
    "ys_pred_s_imp = gb_s_cls2.predict(Xs_test_mat)\n",
    "ys_proba_s_imp = gb_s_cls2.predict_proba(Xs_test_mat)\n",
    "\n",
    "f1_s_imp = f1_score(ys_test, ys_pred_s_imp, zero_division=0)\n",
    "auc_s_imp = roc_auc_score(ys_test, ys_proba_s_imp)\n",
    "\n",
    "print(\"\\n=== Spotify SCRATCH GB improved ===\")\n",
    "print(f\"F1 : {f1_s_imp:.4f}\")\n",
    "print(f\"AUC: {auc_s_imp:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d3039c5-b83c-474a-bd05-581424c3dc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== FINAL SUMMARY LAB 5 =====\n",
      "\n",
      "Walmart (Regression):\n",
      "SKLEARN GB baseline  RMSE=194819.0911, R2=0.8822\n",
      "SKLEARN GB improved  RMSE=118855.8977, R2=0.9561\n",
      "SCRATCH GB baseline  RMSE=202291.4567, R2=0.8730\n",
      "SCRATCH GB improved  RMSE=147868.8385, R2=0.9321\n",
      "\n",
      "Spotify (Classification):\n",
      "SKLEARN GB baseline  F1=0.0048, AUC=0.5018\n",
      "SKLEARN GB improved  F1=0.0355, AUC=0.5026\n",
      "SCRATCH GB baseline  F1=0.0000, AUC=0.4779\n",
      "SCRATCH GB improved  F1=0.0000, AUC=0.4917\n"
     ]
    }
   ],
   "source": [
    "print(\"===== FINAL SUMMARY LAB 5 =====\")\n",
    "\n",
    "print(\"\\nWalmart (Regression):\")\n",
    "print(f\"SKLEARN GB baseline  RMSE={rmse_gb_base:.4f}, R2={r2_gb_base:.4f}\")\n",
    "print(f\"SKLEARN GB improved  RMSE={rmse_gb_imp:.4f}, R2={r2_gb_imp:.4f}\")\n",
    "print(f\"SCRATCH GB baseline  RMSE={rmse_s_base:.4f}, R2={r2_s_base:.4f}\")\n",
    "print(f\"SCRATCH GB improved  RMSE={rmse_s_imp:.4f}, R2={r2_s_imp:.4f}\")\n",
    "\n",
    "print(\"\\nSpotify (Classification):\")\n",
    "print(f\"SKLEARN GB baseline  F1={f1_base:.4f}, AUC={auc_base:.4f}\")\n",
    "print(f\"SKLEARN GB improved  F1={f1_imp:.4f}, AUC={auc_imp:.4f}\")\n",
    "print(f\"SCRATCH GB baseline  F1={f1_s_base:.4f}, AUC={auc_s_base:.4f}\")\n",
    "print(f\"SCRATCH GB improved  F1={f1_s_imp:.4f}, AUC={auc_s_imp:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b0d541-c2bc-4793-88d0-7a0e9d102350",
   "metadata": {},
   "source": [
    "В лабораторной работе был исследован градиентный бустинг для задач регрессии и классификации. Бустинг показал высокое качество за счёт последовательного исправления ошибок предыдущих моделей. Подбор ключевых гиперпараметров (число деревьев, learning_rate, глубина слабых моделей и subsample) позволил улучшить метрики на тестовой выборке.\n",
    "\n",
    "Дополнительно была реализована упрощённая версия бустинга “с нуля”. Результаты scratch-реализации подтвердили общую идею бустинга: увеличение числа итераций при уменьшении шага обучения приводит к более стабильной и точной модели, но увеличивает время обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca3acb-cdcb-42b4-8a85-b705639df218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai_lab_env)",
   "language": "python",
   "name": "knn_lab_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
