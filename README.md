## Лабораторные работы по дисциплине "Прикладные системы и фреймворки искусственного интеллекта"
### Выполнил студент группы М8О-403Б-22 Мудров Павел Федорович

## Описание проделанной работы
В рамках выполнения 5 лабораторных работ были исследованы и сравнены различные модели машинного обучения:
1. **KNN** (k-ближайших соседей)
2. **Линейные модели** (Линейная и Логистическая регрессии)
3. **Дерево решений**
4. **Случайный лес**
5. **Градиентный бустинг**

Для каждой модели были проведены эксперименты на двух датасетах:
- **Классификация**: предсказание трудоустройства разработчиков (73k+ строк, 14+ признаков; после обработки — 100+ признаков)
- **Регрессия**: предсказание питательной ценности продуктов (таблица пищевых характеристик)

Для каждой задачи выполнялись 4 этапа тестирования:
1. Модель **sklearn** на базовом бейзлайне  
2. Модель **sklearn** на новом (улучшенном) бейзлайне  
3. **Самописная** реализация на базовом бейзлайне  
4. **Самописная** реализация на новом (улучшенном) бейзлайне  

---

## Методология

### Базовый бейзлайн
- Минимальная предобработка (кодирование категориальных признаков при необходимости)
- Разделение данных на **train/test** в соотношении **67/33**
- Обучение моделей со стандартными параметрами

### Новый бейзлайн
- Стандартизация числовых признаков (**StandardScaler**) (где применимо)
- Кросс-валидация (**5 folds**)
- Подбор гиперпараметров через **GridSearchCV**
- Для линейных моделей: регуляризация и дополнительные меры против мультиколлинеарности (при необходимости)

---

## Анализ результатов

### Общие наблюдения
- **Ансамблевые методы** (случайный лес и градиентный бустинг) в большинстве случаев демонстрировали наилучшее качество, особенно в задаче классификации, благодаря устойчивости к шуму и способности моделировать сложные зависимости.
- **Линейные модели** показали сильные результаты в регрессии на выбранном датасете, что указывает на выраженную линейную компоненту в данных. При этом регуляризация и корректная обработка признаков заметно повышали стабильность качества.
- **Дерево решений** заметно склонно к переобучению: без контроля глубины и параметров разбиения качество на тесте может падать, поэтому настройка `max_depth`, `min_samples_leaf` и `min_samples_split` является критически важной.
- **KNN** сильно зависит от масштаба признаков, метрики расстояния и параметра `k`. Улучшенный бейзлайн (масштабирование + подбор гиперпараметров) чаще всего давал заметный прирост по метрикам.

### Влияние улучшенного бейзлайна
- Для большинства алгоритмов переход от базового бейзлайна к улучшенному приводил к росту качества за счёт:
  - стандартизации признаков (особенно важно для KNN и линейных моделей),
  - подбора гиперпараметров на кросс-валидации,
  - стабилизации обучения (регуляризация, контроль сложности моделей).
- На отдельных моделях улучшения могли давать меньший эффект, если стандартные параметры уже близки к оптимальным или если датасет хорошо “объясняется” простыми зависимостями.

---

## Общий вывод по всем лабораторным работам
Проведённые исследования пяти моделей машинного обучения показали, что качество моделей в значительной степени определяется как выбранным алгоритмом, так и корректно построенной методологией эксперимента. На практике наиболее стабильные и точные результаты обычно обеспечивают ансамблевые методы (случайный лес и градиентный бустинг), особенно для задач классификации. Для регрессии линейные модели могут демонстрировать очень высокое качество при наличии выраженной линейной зависимости в данных, однако требуют внимательной работы с признаками и регуляризации.

Древовидные модели без настройки склонны к переобучению, поэтому контроль сложности дерева и подбор гиперпараметров являются обязательными шагами. KNN остаётся полезным как простой базовый алгоритм, но сильно зависит от масштабирования и выбора параметров.

Самописные реализации позволили глубже понять принципы работы алгоритмов и подтвердить корректность используемых подходов, а также сравнить поведение собственных моделей с реализациями из sklearn. В целом рекомендуется начинать с простых моделей и бейзлайна, после чего переходить к улучшениям через кросс-валидацию, подбор гиперпараметров и методы борьбы с переобучением.
